{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-19T13:08:15.070927Z",
     "iopub.status.busy": "2023-03-19T13:08:15.070268Z",
     "iopub.status.idle": "2023-03-19T13:08:38.417368Z",
     "shell.execute_reply": "2023-03-19T13:08:38.416212Z",
     "shell.execute_reply.started": "2023-03-19T13:08:15.070887Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data194484  data194709\r\n",
      "^C\r\n"
     ]
    }
   ],
   "source": [
    "# 查看当前挂载的数据集目录, 该目录下的变更重启环境后会自动还原\n",
    "# View dataset directory. \n",
    "# This directory will be recovered automatically after resetting environment. \n",
    "!ls /home/aistudio/data\n",
    "# !tar -xzf ./data/data194484/data_6k.tar.gz\n",
    "!tar -xzf ./data/data194709/data_full.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2023-03-19T01:25:29.493829Z",
     "iopub.status.busy": "2023-03-19T01:25:29.493343Z",
     "iopub.status.idle": "2023-03-19T01:25:29.858962Z",
     "shell.execute_reply": "2023-03-19T01:25:29.857781Z",
     "shell.execute_reply.started": "2023-03-19T01:25:29.493808Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 查看工作区文件, 该目录下的变更将会持久保存. 请及时清理不必要的文件, 避免加载过慢.\n",
    "# View personal work directory. \n",
    "# All changes under this directory will be kept even after reset. \n",
    "# Please clean unnecessary files in time to speed up environment loading. \n",
    "!ls /home/aistudio/work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2023-03-19T01:25:29.861150Z",
     "iopub.status.busy": "2023-03-19T01:25:29.860824Z",
     "iopub.status.idle": "2023-03-19T01:25:37.340029Z",
     "shell.execute_reply": "2023-03-19T01:25:37.339000Z",
     "shell.execute_reply.started": "2023-03-19T01:25:29.861124Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: 无法创建目录\"/home/aistudio/external-libraries\": 文件已存在\r\n",
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\r\n",
      "Collecting beautifulsoup4\r\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/c6/ee/16d6f808f5668317d7c23f942091fbc694bcded6aa39678e5167f61b2ba0/beautifulsoup4-4.11.2-py3-none-any.whl (129 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.4/129.4 kB\u001b[0m \u001b[31m418.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\r\n",
      "\u001b[?25hCollecting soupsieve>1.2\r\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/d2/70/2c92d7bc961ba43b7b21032b7622144de5f97dec14b62226533f6940798e/soupsieve-2.4-py3-none-any.whl (37 kB)\r\n",
      "Installing collected packages: soupsieve, beautifulsoup4\r\n",
      "Successfully installed beautifulsoup4-4.11.2 soupsieve-2.4\r\n",
      "\u001b[33mWARNING: Target directory /home/aistudio/external-libraries/soupsieve-2.4.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /home/aistudio/external-libraries/bs4 already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /home/aistudio/external-libraries/soupsieve already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /home/aistudio/external-libraries/beautifulsoup4-4.11.2.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\r\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.0.1\u001b[0m\r\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "# 如果需要进行持久化安装, 需要使用持久化路径, 如下方代码示例:\n",
    "# If a persistence installation is required, \n",
    "# you need to use the persistence path as the following: \n",
    "!mkdir /home/aistudio/external-libraries\n",
    "!pip install beautifulsoup4 -t /home/aistudio/external-libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 同时添加如下代码, 这样每次环境(kernel)启动的时候只要运行下方代码即可: \n",
    "# Also add the following code, \n",
    "# so that every time the environment (kernel) starts, \n",
    "# just run the following code: \n",
    "import sys \n",
    "sys.path.append('/home/aistudio/external-libraries')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-19T01:25:37.342025Z",
     "iopub.status.busy": "2023-03-19T01:25:37.341712Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/matplotlib/__init__.py:107: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\r\n",
      "  from collections import MutableMapping\r\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/matplotlib/rcsetup.py:20: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\r\n",
      "  from collections import Iterable, Mapping\r\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/matplotlib/colors.py:53: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\r\n",
      "  from collections import Sized\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output prefix: demo/Transformer/prop-[12800, 1.0, 0, 0.0]/expo-7/\r\n",
      "net: Transformer\r\n",
      "LR: 0.0005\r\n",
      "LR decay: True\r\n",
      "Iterations: 200000\r\n",
      "Dropout: 0.0\r\n",
      "Random seed: 2023\r\n",
      "Number of data loaded (reg, sup, shear): 12800 0 0\r\n",
      "Using fixed maxima [4.65, 2.04, 2.37]\r\n",
      "Data stats, input  mean 0.189310, max  1.038964;   targets mean 0.272203 , max 1.000000 \r\n",
      "Training batches: 1240\r\n",
      "Validation batches: 40\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0319 09:26:35.066027   557 gpu_resources.cc:61] Please NOTE: device: 0, GPU Compute Capability: 7.0, Driver API Version: 11.2, Runtime API Version: 11.2\r\n",
      "W0319 09:26:35.070050   557 gpu_resources.cc:91] device: 0, cuDNN Version: 8.2.\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FourierTransformer2D(\r\n",
      "  (dpo): Dropout(p=0.0, axis=None, mode=upscale_in_train)\r\n",
      "  (feat_extract): Identity()\r\n",
      "  (downscaler): Linear(in_features=5, out_features=64, dtype=float32)\r\n",
      "  (upscaler): Identity()\r\n",
      "  (encoder_layers): LayerList(\r\n",
      "    (0): SimpleTransformerEncoderLayer(\r\n",
      "      (attn): SimpleAttention(\r\n",
      "        (linears): LayerList(\r\n",
      "          (0): Linear(in_features=64, out_features=64, dtype=float32)\r\n",
      "          (1): Linear(in_features=64, out_features=64, dtype=float32)\r\n",
      "          (2): Linear(in_features=64, out_features=64, dtype=float32)\r\n",
      "        )\r\n",
      "        (fc): Linear(in_features=72, out_features=64, dtype=float32)\r\n",
      "        (dropout): Dropout(p=0.0, axis=None, mode=upscale_in_train)\r\n",
      "      )\r\n",
      "      (layer_norm1): LayerNorm(normalized_shape=[64], epsilon=1e-05)\r\n",
      "      (layer_norm2): LayerNorm(normalized_shape=[64], epsilon=1e-05)\r\n",
      "      (ff): FeedForward(\r\n",
      "        (lr1): Linear(in_features=64, out_features=128, dtype=float32)\r\n",
      "        (activation): ReLU()\r\n",
      "        (lr2): Linear(in_features=128, out_features=64, dtype=float32)\r\n",
      "        (dropout): Dropout(p=0.0, axis=None, mode=upscale_in_train)\r\n",
      "      )\r\n",
      "      (dropout1): Dropout(p=0.0, axis=None, mode=upscale_in_train)\r\n",
      "      (dropout2): Dropout(p=0.0, axis=None, mode=upscale_in_train)\r\n",
      "    )\r\n",
      "    (1): SimpleTransformerEncoderLayer(\r\n",
      "      (attn): SimpleAttention(\r\n",
      "        (linears): LayerList(\r\n",
      "          (0): Linear(in_features=64, out_features=64, dtype=float32)\r\n",
      "          (1): Linear(in_features=64, out_features=64, dtype=float32)\r\n",
      "          (2): Linear(in_features=64, out_features=64, dtype=float32)\r\n",
      "        )\r\n",
      "        (fc): Linear(in_features=72, out_features=64, dtype=float32)\r\n",
      "        (dropout): Dropout(p=0.0, axis=None, mode=upscale_in_train)\r\n",
      "      )\r\n",
      "      (layer_norm1): LayerNorm(normalized_shape=[64], epsilon=1e-05)\r\n",
      "      (layer_norm2): LayerNorm(normalized_shape=[64], epsilon=1e-05)\r\n",
      "      (ff): FeedForward(\r\n",
      "        (lr1): Linear(in_features=64, out_features=128, dtype=float32)\r\n",
      "        (activation): ReLU()\r\n",
      "        (lr2): Linear(in_features=128, out_features=64, dtype=float32)\r\n",
      "        (dropout): Dropout(p=0.0, axis=None, mode=upscale_in_train)\r\n",
      "      )\r\n",
      "      (dropout1): Dropout(p=0.0, axis=None, mode=upscale_in_train)\r\n",
      "      (dropout2): Dropout(p=0.0, axis=None, mode=upscale_in_train)\r\n",
      "    )\r\n",
      "    (2): SimpleTransformerEncoderLayer(\r\n",
      "      (attn): SimpleAttention(\r\n",
      "        (linears): LayerList(\r\n",
      "          (0): Linear(in_features=64, out_features=64, dtype=float32)\r\n",
      "          (1): Linear(in_features=64, out_features=64, dtype=float32)\r\n",
      "          (2): Linear(in_features=64, out_features=64, dtype=float32)\r\n",
      "        )\r\n",
      "        (fc): Linear(in_features=72, out_features=64, dtype=float32)\r\n",
      "        (dropout): Dropout(p=0.0, axis=None, mode=upscale_in_train)\r\n",
      "      )\r\n",
      "      (layer_norm1): LayerNorm(normalized_shape=[64], epsilon=1e-05)\r\n",
      "      (layer_norm2): LayerNorm(normalized_shape=[64], epsilon=1e-05)\r\n",
      "      (ff): FeedForward(\r\n",
      "        (lr1): Linear(in_features=64, out_features=128, dtype=float32)\r\n",
      "        (activation): ReLU()\r\n",
      "        (lr2): Linear(in_features=128, out_features=64, dtype=float32)\r\n",
      "        (dropout): Dropout(p=0.0, axis=None, mode=upscale_in_train)\r\n",
      "      )\r\n",
      "      (dropout1): Dropout(p=0.0, axis=None, mode=upscale_in_train)\r\n",
      "      (dropout2): Dropout(p=0.0, axis=None, mode=upscale_in_train)\r\n",
      "    )\r\n",
      "    (3): SimpleTransformerEncoderLayer(\r\n",
      "      (attn): SimpleAttention(\r\n",
      "        (linears): LayerList(\r\n",
      "          (0): Linear(in_features=64, out_features=64, dtype=float32)\r\n",
      "          (1): Linear(in_features=64, out_features=64, dtype=float32)\r\n",
      "          (2): Linear(in_features=64, out_features=64, dtype=float32)\r\n",
      "        )\r\n",
      "        (fc): Linear(in_features=72, out_features=64, dtype=float32)\r\n",
      "        (dropout): Dropout(p=0.0, axis=None, mode=upscale_in_train)\r\n",
      "      )\r\n",
      "      (layer_norm1): LayerNorm(normalized_shape=[64], epsilon=1e-05)\r\n",
      "      (layer_norm2): LayerNorm(normalized_shape=[64], epsilon=1e-05)\r\n",
      "      (ff): FeedForward(\r\n",
      "        (lr1): Linear(in_features=64, out_features=128, dtype=float32)\r\n",
      "        (activation): ReLU()\r\n",
      "        (lr2): Linear(in_features=128, out_features=64, dtype=float32)\r\n",
      "        (dropout): Dropout(p=0.0, axis=None, mode=upscale_in_train)\r\n",
      "      )\r\n",
      "      (dropout1): Dropout(p=0.0, axis=None, mode=upscale_in_train)\r\n",
      "      (dropout2): Dropout(p=0.0, axis=None, mode=upscale_in_train)\r\n",
      "    )\r\n",
      "  )\r\n",
      "  (regressor): SpectralRegressor(\r\n",
      "    (activation): GELU(approximate=False)\r\n",
      "    (fc): Linear(in_features=64, out_features=32, dtype=float32)\r\n",
      "    (spectral_conv): LayerList(\r\n",
      "      (0): SpectralConv2d(\r\n",
      "        (dropout): Dropout(p=0.0, axis=None, mode=upscale_in_train)\r\n",
      "        (activation): GELU(approximate=False)\r\n",
      "        (linear): Conv2D(32, 32, kernel_size=[1, 1], data_format=NCHW)\r\n",
      "      )\r\n",
      "      (1): SpectralConv2d(\r\n",
      "        (dropout): Dropout(p=0.0, axis=None, mode=upscale_in_train)\r\n",
      "        (activation): GELU(approximate=False)\r\n",
      "        (linear): Conv2D(32, 32, kernel_size=[1, 1], data_format=NCHW)\r\n",
      "      )\r\n",
      "    )\r\n",
      "    (regressor): Sequential(\r\n",
      "      (0): Linear(in_features=32, out_features=128, dtype=float32)\r\n",
      "      (1): GELU(approximate=False)\r\n",
      "      (2): Linear(in_features=128, out_features=3, dtype=float32)\r\n",
      "    )\r\n",
      "  )\r\n",
      ")\r\n",
      "Initialized TurbNet with 8533731 trainable params \r\n",
      "Starting epoch 1 / 161, LR 0.0005\r\n",
      "Epoch: 0, batch-idx: 39, L1: 0.018753080735088235, L1_val 0.010760407650377602, Cost: 155.59616708755493\r\n",
      "Starting epoch 2 / 161, LR 0.0005\r\n",
      "Epoch: 1, batch-idx: 39, L1: 0.01106365547447856, L1_val 0.008694433444179594, Cost: 192.99407172203064\r\n",
      "Starting epoch 3 / 161, LR 0.0005\r\n",
      "Epoch: 2, batch-idx: 39, L1: 0.009407731456186383, L1_val 0.007942271721549331, Cost: 193.24622631072998\r\n",
      "Starting epoch 4 / 161, LR 0.0005\r\n",
      "Epoch: 3, batch-idx: 39, L1: 0.008674641085165222, L1_val 0.007192573451902717, Cost: 193.32109904289246\r\n",
      "Starting epoch 5 / 161, LR 0.0005\r\n",
      "Epoch: 4, batch-idx: 39, L1: 0.008129787808960124, L1_val 0.007229613041272387, Cost: 193.12741017341614\r\n",
      "Starting epoch 6 / 161, LR 0.0005\r\n",
      "Epoch: 5, batch-idx: 39, L1: 0.00780978876113471, L1_val 0.0069713933684397485, Cost: 193.21443915367126\r\n",
      "Starting epoch 7 / 161, LR 0.0005\r\n",
      "Epoch: 6, batch-idx: 39, L1: 0.0074764666284599735, L1_val 0.008667039300780744, Cost: 192.81911325454712\r\n",
      "Starting epoch 8 / 161, LR 0.0005\r\n",
      "Epoch: 7, batch-idx: 39, L1: 0.0073108996679600805, L1_val 0.006728666392154992, Cost: 193.00550484657288\r\n",
      "Starting epoch 9 / 161, LR 0.0005\r\n",
      "Epoch: 8, batch-idx: 39, L1: 0.0070618258843634036, L1_val 0.006467222335049883, Cost: 193.17462730407715\r\n",
      "Starting epoch 10 / 161, LR 0.0005\r\n",
      "Epoch: 9, batch-idx: 39, L1: 0.006871801127882434, L1_val 0.006311627198010683, Cost: 192.9073977470398\r\n",
      "Starting epoch 11 / 161, LR 0.0005\r\n",
      "Epoch: 10, batch-idx: 39, L1: 0.006709070305242353, L1_val 0.006284531811252237, Cost: 192.9852259159088\r\n",
      "Starting epoch 12 / 161, LR 0.0005\r\n",
      "Epoch: 11, batch-idx: 39, L1: 0.006602250742388048, L1_val 0.008181886945385486, Cost: 192.8437855243683\r\n",
      "Starting epoch 13 / 161, LR 0.0005\r\n",
      "Epoch: 12, batch-idx: 39, L1: 0.00650180185574197, L1_val 0.005505514738615602, Cost: 192.73853206634521\r\n",
      "Starting epoch 14 / 161, LR 0.0005\r\n",
      "Epoch: 13, batch-idx: 39, L1: 0.006378309916509616, L1_val 0.00645181086147204, Cost: 192.88517093658447\r\n",
      "Starting epoch 15 / 161, LR 0.0005\r\n",
      "Epoch: 14, batch-idx: 39, L1: 0.006259194754567298, L1_val 0.0053564725792966785, Cost: 192.85913014411926\r\n",
      "Starting epoch 16 / 161, LR 0.0005\r\n",
      "Epoch: 15, batch-idx: 39, L1: 0.006215640161028733, L1_val 0.005346126935910434, Cost: 192.8825855255127\r\n",
      "Starting epoch 17 / 161, LR 0.0005\r\n",
      "Epoch: 16, batch-idx: 39, L1: 0.006132090542720811, L1_val 0.005999006418278441, Cost: 192.97698140144348\r\n",
      "Starting epoch 18 / 161, LR 0.0005\r\n",
      "Epoch: 17, batch-idx: 39, L1: 0.006044288621389217, L1_val 0.005240933335153386, Cost: 192.83914709091187\r\n",
      "Starting epoch 19 / 161, LR 0.0005\r\n",
      "Epoch: 18, batch-idx: 39, L1: 0.00596651998911834, L1_val 0.005377549899276346, Cost: 192.7242660522461\r\n",
      "Starting epoch 20 / 161, LR 0.0005\r\n",
      "Epoch: 19, batch-idx: 39, L1: 0.005916701734531671, L1_val 0.005553132377099246, Cost: 193.0385024547577\r\n",
      "Starting epoch 21 / 161, LR 0.0005\r\n",
      "Epoch: 20, batch-idx: 39, L1: 0.0058107498629514365, L1_val 0.005895994784077629, Cost: 192.9434459209442\r\n",
      "Starting epoch 22 / 161, LR 0.0005\r\n",
      "Epoch: 21, batch-idx: 39, L1: 0.005774562794061738, L1_val 0.005845538264838979, Cost: 192.9717559814453\r\n",
      "Starting epoch 23 / 161, LR 0.0005\r\n",
      "Epoch: 22, batch-idx: 39, L1: 0.00572494532116839, L1_val 0.005072693072725088, Cost: 192.92355298995972\r\n",
      "Starting epoch 24 / 161, LR 0.0005\r\n",
      "Epoch: 23, batch-idx: 39, L1: 0.0056851708011010724, L1_val 0.005847296415595338, Cost: 192.92556262016296\r\n",
      "Starting epoch 25 / 161, LR 0.0005\r\n",
      "Epoch: 24, batch-idx: 39, L1: 0.005638095657266076, L1_val 0.005477568303467706, Cost: 192.67148685455322\r\n",
      "Starting epoch 26 / 161, LR 0.0005\r\n",
      "Epoch: 25, batch-idx: 39, L1: 0.005564182937978917, L1_val 0.0051388470979873094, Cost: 192.92439770698547\r\n",
      "Starting epoch 27 / 161, LR 0.0005\r\n",
      "Epoch: 26, batch-idx: 39, L1: 0.005524806636704823, L1_val 0.005591599072795361, Cost: 192.98446679115295\r\n",
      "Starting epoch 28 / 161, LR 0.0005\r\n",
      "Epoch: 27, batch-idx: 39, L1: 0.005494140389172601, L1_val 0.005491258489200845, Cost: 192.83594012260437\r\n",
      "Starting epoch 29 / 161, LR 0.0005\r\n",
      "Epoch: 28, batch-idx: 39, L1: 0.0054241122552118595, L1_val 0.004951739480020478, Cost: 192.89198803901672\r\n",
      "Starting epoch 30 / 161, LR 0.0005\r\n",
      "Epoch: 29, batch-idx: 39, L1: 0.005393182127004219, L1_val 0.004980489955050871, Cost: 192.87807297706604\r\n",
      "Starting epoch 31 / 161, LR 0.0005\r\n",
      "Epoch: 30, batch-idx: 39, L1: 0.0053697971101369585, L1_val 0.005451310577336698, Cost: 192.7192142009735\r\n",
      "Starting epoch 32 / 161, LR 0.0005\r\n",
      "Epoch: 31, batch-idx: 39, L1: 0.005322168625876187, L1_val 0.005148311506491155, Cost: 192.95481324195862\r\n",
      "Starting epoch 33 / 161, LR 0.0005\r\n",
      "Epoch: 32, batch-idx: 39, L1: 0.0053013298868937716, L1_val 0.00522979887900874, Cost: 193.09027218818665\r\n",
      "Starting epoch 34 / 161, LR 0.0005\r\n",
      "Epoch: 33, batch-idx: 39, L1: 0.005263639292717281, L1_val 0.00504894649493508, Cost: 193.0085744857788\r\n",
      "Starting epoch 35 / 161, LR 0.0005\r\n",
      "Epoch: 34, batch-idx: 39, L1: 0.005211171577121281, L1_val 0.005116628704126924, Cost: 192.76092648506165\r\n",
      "Starting epoch 36 / 161, LR 0.0005\r\n",
      "Epoch: 35, batch-idx: 39, L1: 0.005195913110735766, L1_val 0.0048542073054704815, Cost: 192.91875672340393\r\n",
      "Starting epoch 37 / 161, LR 0.0005\r\n",
      "Epoch: 36, batch-idx: 39, L1: 0.005138282285488752, L1_val 0.004823501920327544, Cost: 192.85467267036438\r\n",
      "Starting epoch 38 / 161, LR 0.0005\r\n",
      "Epoch: 37, batch-idx: 39, L1: 0.005142658543228472, L1_val 0.005552562803495675, Cost: 192.91746401786804\r\n",
      "Starting epoch 39 / 161, LR 0.0005\r\n",
      "Epoch: 38, batch-idx: 39, L1: 0.0050900939547817315, L1_val 0.004669736817595549, Cost: 192.92717909812927\r\n",
      "Starting epoch 40 / 161, LR 0.0005\r\n",
      "Epoch: 39, batch-idx: 39, L1: 0.005059071004131599, L1_val 0.004915081197395921, Cost: 192.9203712940216\r\n",
      "Starting epoch 41 / 161, LR 0.0005\r\n",
      "Epoch: 40, batch-idx: 39, L1: 0.005013974224247279, L1_val 0.004771048639668152, Cost: 192.93102955818176\r\n",
      "Starting epoch 42 / 161, LR 0.0005\r\n",
      "Epoch: 41, batch-idx: 39, L1: 0.005001643634281091, L1_val 0.005081384856021031, Cost: 193.01341605186462\r\n",
      "Starting epoch 43 / 161, LR 0.0005\r\n",
      "Epoch: 42, batch-idx: 39, L1: 0.004967203878069056, L1_val 0.0044634073099587114, Cost: 192.66930222511292\r\n",
      "Starting epoch 44 / 161, LR 0.0005\r\n",
      "Epoch: 43, batch-idx: 39, L1: 0.004996193007888994, L1_val 0.0045695094857364895, Cost: 193.05255770683289\r\n",
      "Starting epoch 45 / 161, LR 0.0005\r\n",
      "Epoch: 44, batch-idx: 39, L1: 0.004926372002603697, L1_val 0.004669234604807571, Cost: 192.99462795257568\r\n",
      "Starting epoch 46 / 161, LR 0.0005\r\n",
      "Epoch: 45, batch-idx: 39, L1: 0.004900951472940975, L1_val 0.004899787984322756, Cost: 192.92278480529785\r\n",
      "Starting epoch 47 / 161, LR 0.0005\r\n",
      "Epoch: 46, batch-idx: 39, L1: 0.004887635726387792, L1_val 0.005013633298221976, Cost: 192.99831318855286\r\n",
      "Starting epoch 48 / 161, LR 0.0005\r\n",
      "Epoch: 47, batch-idx: 39, L1: 0.004852611176301575, L1_val 0.004822088131913915, Cost: 192.69964790344238\r\n",
      "Starting epoch 49 / 161, LR 0.0005\r\n",
      "Epoch: 48, batch-idx: 39, L1: 0.004822835944228686, L1_val 0.004576000609085895, Cost: 192.98102402687073\r\n",
      "Starting epoch 50 / 161, LR 0.0005\r\n",
      "Epoch: 49, batch-idx: 39, L1: 0.004816782934170577, L1_val 0.0045988374447915705, Cost: 192.97772812843323\r\n",
      "Starting epoch 51 / 161, LR 0.0005\r\n",
      "Epoch: 50, batch-idx: 39, L1: 0.004780213938436411, L1_val 0.004919292940758169, Cost: 192.8894591331482\r\n",
      "Starting epoch 52 / 161, LR 0.0005\r\n",
      "Epoch: 51, batch-idx: 39, L1: 0.004783926284477685, L1_val 0.004478654830018058, Cost: 192.91561102867126\r\n",
      "Starting epoch 53 / 161, LR 0.0005\r\n",
      "Epoch: 52, batch-idx: 39, L1: 0.004722346923024874, L1_val 0.004342603101395071, Cost: 192.87419629096985\r\n",
      "Starting epoch 54 / 161, LR 0.0005\r\n",
      "Epoch: 53, batch-idx: 39, L1: 0.0047223963608567215, L1_val 0.004947743128286675, Cost: 192.7493166923523\r\n",
      "Starting epoch 55 / 161, LR 0.0005\r\n",
      "Epoch: 54, batch-idx: 39, L1: 0.00470755517064038, L1_val 0.004445009212940931, Cost: 193.0614583492279\r\n",
      "Starting epoch 56 / 161, LR 0.0005\r\n",
      "Epoch: 55, batch-idx: 39, L1: 0.004673642813483433, L1_val 0.004662499006371945, Cost: 192.91797161102295\r\n",
      "Starting epoch 57 / 161, LR 0.0005\r\n",
      "Epoch: 56, batch-idx: 39, L1: 0.0046578046080896695, L1_val 0.00481819910928607, Cost: 192.9579038619995\r\n",
      "Starting epoch 58 / 161, LR 0.0005\r\n",
      "Epoch: 57, batch-idx: 39, L1: 0.004629495121996789, L1_val 0.004655585615546442, Cost: 193.16282653808594\r\n",
      "Starting epoch 59 / 161, LR 0.0005\r\n",
      "Epoch: 58, batch-idx: 39, L1: 0.004621163981256916, L1_val 0.004537452338263392, Cost: 192.98899245262146\r\n",
      "Starting epoch 60 / 161, LR 0.0005\r\n",
      "Epoch: 59, batch-idx: 39, L1: 0.004607019578050371, L1_val 0.004580693959724158, Cost: 192.74986219406128\r\n",
      "Starting epoch 61 / 161, LR 0.0005\r\n",
      "Epoch: 60, batch-idx: 39, L1: 0.0045908468874967506, L1_val 0.004519966139923781, Cost: 192.88496828079224\r\n",
      "Starting epoch 62 / 161, LR 0.0005\r\n",
      "Epoch: 61, batch-idx: 39, L1: 0.004594166319622027, L1_val 0.004092861287062988, Cost: 192.90871858596802\r\n",
      "Starting epoch 63 / 161, LR 0.0005\r\n",
      "Epoch: 62, batch-idx: 39, L1: 0.0045384540426312014, L1_val 0.00432496139255818, Cost: 192.8522765636444\r\n",
      "Starting epoch 64 / 161, LR 0.0005\r\n",
      "Epoch: 63, batch-idx: 39, L1: 0.004513724061431393, L1_val 0.004409669319284148, Cost: 192.64600801467896\r\n",
      "Starting epoch 65 / 161, LR 0.0005\r\n",
      "Epoch: 64, batch-idx: 39, L1: 0.004525068781672857, L1_val 0.004667959152720868, Cost: 192.82549118995667\r\n",
      "Starting epoch 66 / 161, LR 0.0005\r\n",
      "Epoch: 65, batch-idx: 39, L1: 0.004522813506604683, L1_val 0.004694176459452137, Cost: 192.6744589805603\r\n",
      "Starting epoch 67 / 161, LR 0.0005\r\n",
      "Epoch: 66, batch-idx: 39, L1: 0.004493143134130796, L1_val 0.0041752385266590865, Cost: 192.91142344474792\r\n",
      "Starting epoch 68 / 161, LR 0.0005\r\n",
      "Epoch: 67, batch-idx: 39, L1: 0.004461403828369633, L1_val 0.004302794270915911, Cost: 193.12320017814636\r\n",
      "Starting epoch 69 / 161, LR 0.0005\r\n",
      "Epoch: 68, batch-idx: 39, L1: 0.004427501938170603, L1_val 0.00428569734795019, Cost: 192.94703912734985\r\n",
      "Starting epoch 70 / 161, LR 0.0005\r\n",
      "Epoch: 69, batch-idx: 39, L1: 0.004432422631033396, L1_val 0.003976073203375563, Cost: 192.98110270500183\r\n",
      "Starting epoch 71 / 161, LR 0.0005\r\n",
      "Epoch: 70, batch-idx: 39, L1: 0.004406245740603716, L1_val 0.004137022135546431, Cost: 193.1979250907898\r\n",
      "Starting epoch 72 / 161, LR 0.0005\r\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import os, sys, random, time\n",
    "import numpy as np\n",
    "import paddle\n",
    "import paddle.nn as nn\n",
    "from paddle.io import DataLoader\n",
    "import paddle.optimizer as optim\n",
    "from matplotlib import cm\n",
    "\n",
    "from Unet_model import UNet2d\n",
    "from FNO_model import FNO2d\n",
    "from Trans_model import FourierTransformer2D\n",
    "import read_data\n",
    "import utils\n",
    "\n",
    "######## Settings ########\n",
    "\n",
    "# 总体迭代步数，原文采用80k，这里采用200k，注意训练的epoch采用iterations进行运算，以避免不同训练集大小优化步数不同\n",
    "iterations = 200000\n",
    "# batch size\n",
    "batch_size = 10\n",
    "# learning rate, generator\n",
    "lrG = 0.0005\n",
    "# decay learning rate?\n",
    "decayLr = True\n",
    "# channel exponent to control network size，注意仅用于UNet，对FNO和Transformer不起作用\n",
    "expo = 7\n",
    "# data set config  第一个位置为总体样本数量，后三个数表示从reg/sup/shear三个文件夹选择的样本比例，和为1\n",
    "# prop = None  # by default, use all from \"../data/train\"\n",
    "prop = [12800, 1.0, 0, 0.0]\n",
    "# save txt files with per epoch loss?\n",
    "saveL1 = True\n",
    "# model type UNet/FNO/Transformer\n",
    "net = 'Transformer'\n",
    "# data path\n",
    "data_path = os.path.join('data')\n",
    "\n",
    "##########################\n",
    "\n",
    "work_path = os.path.join('demo', net, \"prop-\" + str(prop), \"expo-\" + str(expo))\n",
    "\n",
    "prefix = work_path + \"/\"\n",
    "utils.makeDirs([prefix])\n",
    "print(\"Output prefix: {}\".format(prefix))\n",
    "\n",
    "dropout = 0.  # note, the original runs from https://arxiv.org/abs/1810.08217 used slight dropout, but the effect is minimal; conv layers \"shouldn't need\" dropout, hence set to 0 here.\n",
    "doLoad = \"\"  # optional, path to pre-trained model\n",
    "print(\"net: {}\".format(net))\n",
    "print(\"LR: {}\".format(lrG))\n",
    "print(\"LR decay: {}\".format(decayLr))\n",
    "print(\"Iterations: {}\".format(iterations))\n",
    "print(\"Dropout: {}\".format(dropout))\n",
    "\n",
    "##########################\n",
    "\n",
    "# seed = random.randint(0, 2 ** 32 - 1)\n",
    "seed = 2023 \n",
    "print(\"Random seed: {}\".format(seed))\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "paddle.seed(seed)\n",
    "# paddle.cuda.manual_seed_all(seed)\n",
    "# torch.backends.cudnn.deterministic=True # warning, slower\n",
    "\n",
    "# create pytorch data object with dfp dataset\n",
    "train_path = os.path.join(data_path, 'train/')\n",
    "valid_path = os.path.join(data_path, 'test/')\n",
    "data = read_data.TurbDataset(prop, shuffle=1, dataDir=train_path, dataDirTest=valid_path)\n",
    "trainLoader = DataLoader(data, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "print(\"Training batches: {}\".format(len(trainLoader)))\n",
    "dataValidation = read_data.ValiDataset(data)\n",
    "validLoader = DataLoader(dataValidation, batch_size=batch_size, shuffle=False, drop_last=True)\n",
    "print(\"Validation batches: {}\".format(len(validLoader)))\n",
    "\n",
    "# setup training\n",
    "epochs = int(iterations / len(trainLoader) + 0.5)\n",
    "if 'UNet' in net:\n",
    "    net_model = UNet2d(channelExponent=expo, dropout=dropout)\n",
    "elif 'FNO' in net:\n",
    "    net_model = FNO2d(in_dim=3, out_dim=3, modes=(32, 32), width=32, depth=4, steps=1, padding=4,\n",
    "                        activation='gelu')\n",
    "elif 'Transformer' in net:\n",
    "    import yaml\n",
    "\n",
    "    with open(os.path.join('transformer_config.yml')) as f:\n",
    "        config = yaml.full_load(f)\n",
    "    config = config['Transformer']\n",
    "    net_model = FourierTransformer2D(**config)\n",
    "\n",
    "print(net_model)  # print full net\n",
    "model_parameters = filter(lambda p: ~p.stop_gradient, net_model.parameters())\n",
    "params = sum([np.prod(p.shape) for p in model_parameters])\n",
    "print(\"Initialized TurbNet with {} trainable params \".format(params))\n",
    "\n",
    "if len(doLoad) > 0:\n",
    "    net_model.load_state_dict(paddle.load(doLoad))\n",
    "    print(\"Loaded model \" + doLoad)\n",
    "\n",
    "criterionL1 = nn.L1Loss()\n",
    "optimizerG = optim.Adam(parameters=net_model.parameters(), learning_rate=lrG, beta1=0.5, beta2=0.999,\n",
    "                        weight_decay=0.0)\n",
    "\n",
    "##########################\n",
    "\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    star_time = time.time()\n",
    "    # compute LR decay\n",
    "    if decayLr:\n",
    "        currLr = utils.computeLR(epoch, epochs, lrG * 0.1, lrG)\n",
    "        optimizerG.set_lr(currLr)\n",
    "\n",
    "    logline = \"Starting epoch {} / {}, LR {}\".format((epoch + 1), epochs, currLr)\n",
    "    print(logline)\n",
    "\n",
    "    net_model.train()\n",
    "    L1_accum = 0.0\n",
    "    for i, traindata in enumerate(trainLoader, 0):\n",
    "        inputs, targets = traindata\n",
    "\n",
    "        optimizerG.clear_grad()\n",
    "        gen_out = net_model(inputs)\n",
    "\n",
    "        lossL1 = criterionL1(gen_out, targets)\n",
    "        lossL1.backward()\n",
    "\n",
    "        optimizerG.step()\n",
    "\n",
    "        lossL1viz = lossL1.item()\n",
    "        L1_accum += lossL1viz\n",
    "\n",
    "    # validation\n",
    "    net_model.eval()\n",
    "    L1val_accum = 0.0\n",
    "    for i, validata in enumerate(validLoader, 0):\n",
    "        inputs, targets = validata\n",
    "        with paddle.no_grad():\n",
    "            outputs = net_model(inputs)\n",
    "            lossL1 = criterionL1(outputs, targets)\n",
    "            L1val_accum += lossL1.item()\n",
    "\n",
    "    # data for graph plotting\n",
    "    L1_accum /= len(trainLoader)\n",
    "    L1val_accum /= len(validLoader)\n",
    "\n",
    "    logline = \"Epoch: {}, batch-idx: {}, L1: {}, L1_val {}, Cost: {}\" \\\n",
    "        .format(epoch, i, L1_accum, L1val_accum, time.time() - star_time)\n",
    "    print(logline)\n",
    "\n",
    "    if saveL1:\n",
    "        if epoch == 0:\n",
    "            utils.resetLog(prefix + \"L1tra.txt\")\n",
    "            utils.resetLog(prefix + \"L1val.txt\")\n",
    "        utils.log(prefix + \"L1tra.txt\", \"{} \".format(L1_accum), False)\n",
    "        utils.log(prefix + \"L1val.txt\", \"{} \".format(L1val_accum), False)\n",
    "\n",
    "    if epoch % 10 == 0:\n",
    "\n",
    "        for show_id in range(batch_size):\n",
    "            input_ndarray = inputs.numpy()[show_id]\n",
    "            v_norm = (np.max(np.abs(input_ndarray[0, :, :])) ** 2 +\n",
    "                        np.max(np.abs(input_ndarray[1, :, :])) ** 2) ** 0.5\n",
    "\n",
    "            outputs_denormalized = data.denormalize(outputs.numpy()[show_id], v_norm)\n",
    "            targets_denormalized = data.denormalize(targets.numpy()[show_id], v_norm)\n",
    "            utils.makeDirs([prefix + \"results_train\"])\n",
    "            utils.imageOut(prefix + \"results_train/show-{}\".format(show_id), outputs_denormalized,\n",
    "                            targets_denormalized, saveTargets=True, cmap=cm.RdBu_r)\n",
    "\n",
    "paddle.save(net_model.state_dict(), prefix + \"net_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-19T12:04:12.613269Z",
     "iopub.status.busy": "2023-03-19T12:04:12.612607Z",
     "iopub.status.idle": "2023-03-19T12:07:56.378623Z",
     "shell.execute_reply": "2023-03-19T12:07:56.377785Z",
     "shell.execute_reply.started": "2023-03-19T12:04:12.613192Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of data loaded (reg, sup, shear): 12800 0 0\r\n",
      "Using fixed maxima [4.65, 2.04, 2.37]\r\n",
      "Data stats, input  mean 0.189263, max  1.014262;   targets mean 0.270640 , max 1.000000 \r\n",
      "Validation batches: 400\r\n",
      "Number of data loaded (reg, sup, shear): 12800 0 0\r\n",
      "Using fixed maxima [4.65, 2.04, 2.37]\r\n",
      "Data stats, input  mean 0.190220, max  0.961052;   targets mean 0.289502 , max 1.000000 \r\n",
      "Output prefix: demo/UNet/prop-[12800, 1.0, 0, 0.0]/expo-7/\r\n",
      "Loading demo/UNet/prop-[12800, 1.0, 0, 0.0]/expo-7/net_model\r\n",
      "Loaded demo/UNet/prop-[12800, 1.0, 0, 0.0]/expo-7/net_model\r\n",
      "Test sample 0\r\n",
      "    pressure:  abs. difference, ratio: 7.185699 , 0.061665 \r\n",
      "    velocity:  abs. difference, ratio: 33.834564 , 0.003996 \r\n",
      "    aggregate: abs. difference, ratio: 41.020264 , 0.004779 \r\n",
      "Test sample 1\r\n",
      "    pressure:  abs. difference, ratio: 11.782101 , 0.030640 \r\n",
      "    velocity:  abs. difference, ratio: 57.174919 , 0.006369 \r\n",
      "    aggregate: abs. difference, ratio: 68.957024 , 0.007366 \r\n",
      "Test sample 2\r\n",
      "    pressure:  abs. difference, ratio: 26.757519 , 0.031550 \r\n",
      "    velocity:  abs. difference, ratio: 102.618965 , 0.011098 \r\n",
      "    aggregate: abs. difference, ratio: 129.376480 , 0.012816 \r\n",
      "Test sample 3\r\n",
      "    pressure:  abs. difference, ratio: 17.226746 , 0.080037 \r\n",
      "    velocity:  abs. difference, ratio: 95.917839 , 0.010874 \r\n",
      "    aggregate: abs. difference, ratio: 113.144592 , 0.012521 \r\n",
      "Test sample 4\r\n",
      "    pressure:  abs. difference, ratio: 23.796059 , 0.050279 \r\n",
      "    velocity:  abs. difference, ratio: 103.875732 , 0.011511 \r\n",
      "    aggregate: abs. difference, ratio: 127.671791 , 0.013443 \r\n",
      "Test sample 5\r\n",
      "    pressure:  abs. difference, ratio: 22.764078 , 0.208972 \r\n",
      "    velocity:  abs. difference, ratio: 78.132126 , 0.009531 \r\n",
      "    aggregate: abs. difference, ratio: 100.896202 , 0.012147 \r\n",
      "Test sample 6\r\n",
      "    pressure:  abs. difference, ratio: 13.593351 , 0.022052 \r\n",
      "    velocity:  abs. difference, ratio: 48.616386 , 0.005209 \r\n",
      "    aggregate: abs. difference, ratio: 62.209736 , 0.006252 \r\n",
      "Test sample 7\r\n",
      "    pressure:  abs. difference, ratio: 8.387763 , 0.022910 \r\n",
      "    velocity:  abs. difference, ratio: 25.157246 , 0.002890 \r\n",
      "    aggregate: abs. difference, ratio: 33.545010 , 0.003698 \r\n",
      "Test sample 8\r\n",
      "    pressure:  abs. difference, ratio: 8.687827 , 0.019335 \r\n",
      "    velocity:  abs. difference, ratio: 32.547310 , 0.003613 \r\n",
      "    aggregate: abs. difference, ratio: 41.235138 , 0.004360 \r\n",
      "Test sample 9\r\n",
      "    pressure:  abs. difference, ratio: 100.600952 , 0.175350 \r\n",
      "    velocity:  abs. difference, ratio: 319.878296 , 0.034890 \r\n",
      "    aggregate: abs. difference, ratio: 420.479248 , 0.043162 \r\n",
      "Test sample 10\r\n",
      "    pressure:  abs. difference, ratio: 546.479980 , 0.582881 \r\n",
      "    velocity:  abs. difference, ratio: 1684.048096 , 0.173112 \r\n",
      "    aggregate: abs. difference, ratio: 2230.528076 , 0.209132 \r\n",
      "Test sample 11\r\n",
      "    pressure:  abs. difference, ratio: 513.970825 , 0.618872 \r\n",
      "    velocity:  abs. difference, ratio: 1826.859985 , 0.187634 \r\n",
      "    aggregate: abs. difference, ratio: 2340.830566 , 0.221527 \r\n",
      "Test sample 12\r\n",
      "    pressure:  abs. difference, ratio: 20.953337 , 0.054405 \r\n",
      "    velocity:  abs. difference, ratio: 91.616302 , 0.009916 \r\n",
      "    aggregate: abs. difference, ratio: 112.569641 , 0.011696 \r\n",
      "Test sample 13\r\n",
      "    pressure:  abs. difference, ratio: 16.674976 , 0.042462 \r\n",
      "    velocity:  abs. difference, ratio: 67.899002 , 0.007676 \r\n",
      "    aggregate: abs. difference, ratio: 84.573982 , 0.009155 \r\n",
      "Test sample 14\r\n",
      "    pressure:  abs. difference, ratio: 10.549152 , 0.063305 \r\n",
      "    velocity:  abs. difference, ratio: 46.077820 , 0.005337 \r\n",
      "    aggregate: abs. difference, ratio: 56.626980 , 0.006435 \r\n",
      "Test sample 15\r\n",
      "    pressure:  abs. difference, ratio: 7.287931 , 0.110899 \r\n",
      "    velocity:  abs. difference, ratio: 28.527370 , 0.003487 \r\n",
      "    aggregate: abs. difference, ratio: 35.815304 , 0.004343 \r\n",
      "Test sample 16\r\n",
      "    pressure:  abs. difference, ratio: 7.279576 , 0.042452 \r\n",
      "    velocity:  abs. difference, ratio: 27.005451 , 0.003152 \r\n",
      "    aggregate: abs. difference, ratio: 34.285030 , 0.003923 \r\n",
      "Test sample 17\r\n",
      "    pressure:  abs. difference, ratio: 92.412682 , 0.079893 \r\n",
      "    velocity:  abs. difference, ratio: 270.857056 , 0.028831 \r\n",
      "    aggregate: abs. difference, ratio: 363.269745 , 0.034428 \r\n",
      "Test sample 18\r\n",
      "    pressure:  abs. difference, ratio: 12.528282 , 0.029035 \r\n",
      "    velocity:  abs. difference, ratio: 48.425552 , 0.005344 \r\n",
      "    aggregate: abs. difference, ratio: 60.953835 , 0.006421 \r\n",
      "Test sample 19\r\n",
      "    pressure:  abs. difference, ratio: 7.310449 , 0.079776 \r\n",
      "    velocity:  abs. difference, ratio: 28.243423 , 0.003470 \r\n",
      "    aggregate: abs. difference, ratio: 35.553871 , 0.004320 \r\n",
      "Test sample 20\r\n",
      "    pressure:  abs. difference, ratio: 12.646515 , 0.064041 \r\n",
      "    velocity:  abs. difference, ratio: 46.479088 , 0.005561 \r\n",
      "    aggregate: abs. difference, ratio: 59.125603 , 0.006911 \r\n",
      "Test sample 21\r\n",
      "    pressure:  abs. difference, ratio: 28.802731 , 0.092170 \r\n",
      "    velocity:  abs. difference, ratio: 92.260864 , 0.010434 \r\n",
      "    aggregate: abs. difference, ratio: 121.063591 , 0.013225 \r\n",
      "Test sample 22\r\n",
      "    pressure:  abs. difference, ratio: 9.640153 , 0.037648 \r\n",
      "    velocity:  abs. difference, ratio: 40.145203 , 0.004628 \r\n",
      "    aggregate: abs. difference, ratio: 49.785355 , 0.005575 \r\n",
      "Test sample 23\r\n",
      "    pressure:  abs. difference, ratio: 32.000557 , 0.084383 \r\n",
      "    velocity:  abs. difference, ratio: 99.367447 , 0.010965 \r\n",
      "    aggregate: abs. difference, ratio: 131.368011 , 0.013914 \r\n",
      "Test sample 24\r\n",
      "    pressure:  abs. difference, ratio: 7.872152 , 0.101406 \r\n",
      "    velocity:  abs. difference, ratio: 27.287128 , 0.003333 \r\n",
      "    aggregate: abs. difference, ratio: 35.159279 , 0.004254 \r\n",
      "Test sample 25\r\n",
      "    pressure:  abs. difference, ratio: 42.002960 , 0.146404 \r\n",
      "    velocity:  abs. difference, ratio: 133.875153 , 0.015251 \r\n",
      "    aggregate: abs. difference, ratio: 175.878113 , 0.019401 \r\n",
      "Test sample 26\r\n",
      "    pressure:  abs. difference, ratio: 11.949653 , 0.046914 \r\n",
      "    velocity:  abs. difference, ratio: 42.004906 , 0.004982 \r\n",
      "    aggregate: abs. difference, ratio: 53.954552 , 0.006212 \r\n",
      "Test sample 27\r\n",
      "    pressure:  abs. difference, ratio: 279.558655 , 0.291681 \r\n",
      "    velocity:  abs. difference, ratio: 762.711670 , 0.078097 \r\n",
      "    aggregate: abs. difference, ratio: 1042.270264 , 0.097184 \r\n",
      "Test sample 28\r\n",
      "    pressure:  abs. difference, ratio: 15.072668 , 0.041873 \r\n",
      "    velocity:  abs. difference, ratio: 33.127048 , 0.003905 \r\n",
      "    aggregate: abs. difference, ratio: 48.199715 , 0.005451 \r\n",
      "Test sample 29\r\n",
      "    pressure:  abs. difference, ratio: 12.818604 , 0.040439 \r\n",
      "    velocity:  abs. difference, ratio: 37.236752 , 0.004439 \r\n",
      "    aggregate: abs. difference, ratio: 50.055359 , 0.005750 \r\n",
      "Test sample 30\r\n",
      "    pressure:  abs. difference, ratio: 54.490097 , 0.183011 \r\n",
      "    velocity:  abs. difference, ratio: 179.805603 , 0.020354 \r\n",
      "    aggregate: abs. difference, ratio: 234.295715 , 0.025658 \r\n",
      "Test sample 31\r\n",
      "    pressure:  abs. difference, ratio: 46.559696 , 0.159901 \r\n",
      "    velocity:  abs. difference, ratio: 142.074066 , 0.016542 \r\n",
      "    aggregate: abs. difference, ratio: 188.633759 , 0.021242 \r\n",
      "Test sample 32\r\n",
      "    pressure:  abs. difference, ratio: 48.163704 , 0.162941 \r\n",
      "    velocity:  abs. difference, ratio: 149.594666 , 0.017357 \r\n",
      "    aggregate: abs. difference, ratio: 197.758362 , 0.022185 \r\n",
      "Test sample 33\r\n",
      "    pressure:  abs. difference, ratio: 7.388903 , 0.046817 \r\n",
      "    velocity:  abs. difference, ratio: 37.413597 , 0.004454 \r\n",
      "    aggregate: abs. difference, ratio: 44.802498 , 0.005235 \r\n",
      "Test sample 34\r\n",
      "    pressure:  abs. difference, ratio: 9.955475 , 0.027221 \r\n",
      "    velocity:  abs. difference, ratio: 42.268578 , 0.004717 \r\n",
      "    aggregate: abs. difference, ratio: 52.224052 , 0.005600 \r\n",
      "Test sample 35\r\n",
      "    pressure:  abs. difference, ratio: 10.690566 , 0.029239 \r\n",
      "    velocity:  abs. difference, ratio: 48.355141 , 0.005393 \r\n",
      "    aggregate: abs. difference, ratio: 59.045708 , 0.006327 \r\n",
      "Test sample 36\r\n",
      "    pressure:  abs. difference, ratio: 43.445808 , 0.083539 \r\n",
      "    velocity:  abs. difference, ratio: 116.994797 , 0.012491 \r\n",
      "    aggregate: abs. difference, ratio: 160.440598 , 0.016228 \r\n",
      "Test sample 37\r\n",
      "    pressure:  abs. difference, ratio: 18.843178 , 0.099160 \r\n",
      "    velocity:  abs. difference, ratio: 60.587669 , 0.006842 \r\n",
      "    aggregate: abs. difference, ratio: 79.430847 , 0.008782 \r\n",
      "Test sample 38\r\n",
      "    pressure:  abs. difference, ratio: 22.404419 , 0.128855 \r\n",
      "    velocity:  abs. difference, ratio: 75.545441 , 0.009250 \r\n",
      "    aggregate: abs. difference, ratio: 97.949860 , 0.011743 \r\n",
      "Test sample 39\r\n",
      "    pressure:  abs. difference, ratio: 136.816132 , 0.109578 \r\n",
      "    velocity:  abs. difference, ratio: 427.243408 , 0.044665 \r\n",
      "    aggregate: abs. difference, ratio: 564.059570 , 0.052159 \r\n",
      "Test sample 40\r\n",
      "    pressure:  abs. difference, ratio: 32.674465 , 0.070833 \r\n",
      "    velocity:  abs. difference, ratio: 50.184456 , 0.005504 \r\n",
      "    aggregate: abs. difference, ratio: 82.858917 , 0.008651 \r\n",
      "Test sample 41\r\n",
      "    pressure:  abs. difference, ratio: 121.614464 , 0.101615 \r\n",
      "    velocity:  abs. difference, ratio: 354.727478 , 0.037996 \r\n",
      "    aggregate: abs. difference, ratio: 476.341919 , 0.045225 \r\n",
      "Test sample 42\r\n",
      "    pressure:  abs. difference, ratio: 13.202461 , 0.124137 \r\n",
      "    velocity:  abs. difference, ratio: 58.493286 , 0.006923 \r\n",
      "    aggregate: abs. difference, ratio: 71.695747 , 0.008380 \r\n",
      "Test sample 43\r\n",
      "    pressure:  abs. difference, ratio: 9.091559 , 0.085403 \r\n",
      "    velocity:  abs. difference, ratio: 35.472450 , 0.004285 \r\n",
      "    aggregate: abs. difference, ratio: 44.564011 , 0.005314 \r\n",
      "Test sample 44\r\n",
      "    pressure:  abs. difference, ratio: 10.387477 , 0.028585 \r\n",
      "    velocity:  abs. difference, ratio: 40.052849 , 0.004544 \r\n",
      "    aggregate: abs. difference, ratio: 50.440323 , 0.005495 \r\n",
      "Test sample 45\r\n",
      "    pressure:  abs. difference, ratio: 8.734104 , 0.045240 \r\n",
      "    velocity:  abs. difference, ratio: 39.000313 , 0.004699 \r\n",
      "    aggregate: abs. difference, ratio: 47.734417 , 0.005621 \r\n",
      "Test sample 46\r\n",
      "    pressure:  abs. difference, ratio: 60.511227 , 0.051930 \r\n",
      "    velocity:  abs. difference, ratio: 131.718582 , 0.013902 \r\n",
      "    aggregate: abs. difference, ratio: 192.229813 , 0.018067 \r\n",
      "Test sample 47\r\n",
      "    pressure:  abs. difference, ratio: 41.740486 , 0.084291 \r\n",
      "    velocity:  abs. difference, ratio: 142.145096 , 0.015892 \r\n",
      "    aggregate: abs. difference, ratio: 183.885590 , 0.019480 \r\n",
      "Test sample 48\r\n",
      "    pressure:  abs. difference, ratio: 14.718953 , 0.072141 \r\n",
      "    velocity:  abs. difference, ratio: 63.444042 , 0.007721 \r\n",
      "    aggregate: abs. difference, ratio: 78.162994 , 0.009281 \r\n",
      "Test sample 49\r\n",
      "    pressure:  abs. difference, ratio: 15.253328 , 0.119388 \r\n",
      "    velocity:  abs. difference, ratio: 59.893318 , 0.007064 \r\n",
      "    aggregate: abs. difference, ratio: 75.146645 , 0.008732 \r\n",
      "Test sample 50\r\n",
      "    pressure:  abs. difference, ratio: 26.323614 , 0.051592 \r\n",
      "    velocity:  abs. difference, ratio: 68.394363 , 0.007630 \r\n",
      "    aggregate: abs. difference, ratio: 94.717979 , 0.009997 \r\n",
      "Test sample 51\r\n",
      "    pressure:  abs. difference, ratio: 13.027596 , 0.032880 \r\n",
      "    velocity:  abs. difference, ratio: 57.569733 , 0.006628 \r\n",
      "    aggregate: abs. difference, ratio: 70.597328 , 0.007773 \r\n",
      "Test sample 52\r\n",
      "    pressure:  abs. difference, ratio: 15.797279 , 0.048416 \r\n",
      "    velocity:  abs. difference, ratio: 46.842609 , 0.005310 \r\n",
      "    aggregate: abs. difference, ratio: 62.639885 , 0.006847 \r\n",
      "Test sample 53\r\n",
      "    pressure:  abs. difference, ratio: 23.294029 , 0.041681 \r\n",
      "    velocity:  abs. difference, ratio: 64.024933 , 0.007071 \r\n",
      "    aggregate: abs. difference, ratio: 87.318954 , 0.009083 \r\n",
      "Test sample 54\r\n",
      "    pressure:  abs. difference, ratio: 72.193245 , 0.097468 \r\n",
      "    velocity:  abs. difference, ratio: 234.975311 , 0.025449 \r\n",
      "    aggregate: abs. difference, ratio: 307.168579 , 0.030797 \r\n",
      "Test sample 55\r\n",
      "    pressure:  abs. difference, ratio: 74.551636 , 0.111186 \r\n",
      "    velocity:  abs. difference, ratio: 246.327148 , 0.026881 \r\n",
      "    aggregate: abs. difference, ratio: 320.878754 , 0.032629 \r\n",
      "Test sample 56\r\n",
      "    pressure:  abs. difference, ratio: 81.459946 , 0.119557 \r\n",
      "    velocity:  abs. difference, ratio: 282.373779 , 0.030851 \r\n",
      "    aggregate: abs. difference, ratio: 363.833710 , 0.036997 \r\n",
      "Test sample 57\r\n",
      "    pressure:  abs. difference, ratio: 6.055508 , 0.079137 \r\n",
      "    velocity:  abs. difference, ratio: 28.213070 , 0.003352 \r\n",
      "    aggregate: abs. difference, ratio: 34.268578 , 0.004034 \r\n",
      "Test sample 58\r\n",
      "    pressure:  abs. difference, ratio: 20.584200 , 0.080218 \r\n",
      "    velocity:  abs. difference, ratio: 84.263794 , 0.009632 \r\n",
      "    aggregate: abs. difference, ratio: 104.848007 , 0.011643 \r\n",
      "Test sample 59\r\n",
      "    pressure:  abs. difference, ratio: 34.890778 , 0.055883 \r\n",
      "    velocity:  abs. difference, ratio: 110.265587 , 0.011961 \r\n",
      "    aggregate: abs. difference, ratio: 145.156372 , 0.014747 \r\n",
      "Test sample 60\r\n",
      "    pressure:  abs. difference, ratio: 21.312099 , 0.056304 \r\n",
      "    velocity:  abs. difference, ratio: 85.855858 , 0.009987 \r\n",
      "    aggregate: abs. difference, ratio: 107.167953 , 0.011940 \r\n",
      "Test sample 61\r\n",
      "    pressure:  abs. difference, ratio: 17.016306 , 0.031454 \r\n",
      "    velocity:  abs. difference, ratio: 65.486099 , 0.007230 \r\n",
      "    aggregate: abs. difference, ratio: 82.502403 , 0.008595 \r\n",
      "Test sample 62\r\n",
      "    pressure:  abs. difference, ratio: 18.950468 , 0.035037 \r\n",
      "    velocity:  abs. difference, ratio: 103.311134 , 0.011040 \r\n",
      "    aggregate: abs. difference, ratio: 122.261597 , 0.012351 \r\n",
      "Test sample 63\r\n",
      "    pressure:  abs. difference, ratio: 12.903453 , 0.053898 \r\n",
      "    velocity:  abs. difference, ratio: 61.313362 , 0.006941 \r\n",
      "    aggregate: abs. difference, ratio: 74.216820 , 0.008180 \r\n",
      "Test sample 64\r\n",
      "    pressure:  abs. difference, ratio: 36.046650 , 0.058419 \r\n",
      "    velocity:  abs. difference, ratio: 110.424515 , 0.012001 \r\n",
      "    aggregate: abs. difference, ratio: 146.471161 , 0.014918 \r\n",
      "Test sample 65\r\n",
      "    pressure:  abs. difference, ratio: 20.798882 , 0.083398 \r\n",
      "    velocity:  abs. difference, ratio: 102.961807 , 0.011740 \r\n",
      "    aggregate: abs. difference, ratio: 123.760696 , 0.013722 \r\n",
      "Test sample 66\r\n",
      "    pressure:  abs. difference, ratio: 15.796469 , 0.089219 \r\n",
      "    velocity:  abs. difference, ratio: 35.078712 , 0.004288 \r\n",
      "    aggregate: abs. difference, ratio: 50.875183 , 0.006087 \r\n",
      "Test sample 67\r\n",
      "    pressure:  abs. difference, ratio: 9.035442 , 0.049990 \r\n",
      "    velocity:  abs. difference, ratio: 30.601980 , 0.003450 \r\n",
      "    aggregate: abs. difference, ratio: 39.637424 , 0.004380 \r\n",
      "Test sample 68\r\n",
      "    pressure:  abs. difference, ratio: 120.891495 , 0.191638 \r\n",
      "    velocity:  abs. difference, ratio: 621.023254 , 0.065591 \r\n",
      "    aggregate: abs. difference, ratio: 741.914734 , 0.073464 \r\n",
      "Test sample 69\r\n",
      "    pressure:  abs. difference, ratio: 27.958733 , 0.068191 \r\n",
      "    velocity:  abs. difference, ratio: 76.529167 , 0.008184 \r\n",
      "    aggregate: abs. difference, ratio: 104.487907 , 0.010705 \r\n",
      "Test sample 70\r\n",
      "    pressure:  abs. difference, ratio: 15.071609 , 0.111131 \r\n",
      "    velocity:  abs. difference, ratio: 57.463985 , 0.007057 \r\n",
      "    aggregate: abs. difference, ratio: 72.535599 , 0.008761 \r\n",
      "Test sample 71\r\n",
      "    pressure:  abs. difference, ratio: 18.795498 , 0.105676 \r\n",
      "    velocity:  abs. difference, ratio: 76.322693 , 0.009127 \r\n",
      "    aggregate: abs. difference, ratio: 95.118187 , 0.011137 \r\n",
      "Test sample 72\r\n",
      "    pressure:  abs. difference, ratio: 151.877228 , 0.189508 \r\n",
      "    velocity:  abs. difference, ratio: 475.898499 , 0.051670 \r\n",
      "    aggregate: abs. difference, ratio: 627.775757 , 0.062704 \r\n",
      "Test sample 73\r\n",
      "    pressure:  abs. difference, ratio: 125.688782 , 0.175965 \r\n",
      "    velocity:  abs. difference, ratio: 414.657776 , 0.045133 \r\n",
      "    aggregate: abs. difference, ratio: 540.346558 , 0.054571 \r\n",
      "Test sample 74\r\n",
      "    pressure:  abs. difference, ratio: 7.083558 , 0.023354 \r\n",
      "    velocity:  abs. difference, ratio: 37.644245 , 0.004334 \r\n",
      "    aggregate: abs. difference, ratio: 44.727806 , 0.004976 \r\n",
      "Test sample 75\r\n",
      "    pressure:  abs. difference, ratio: 41.964218 , 0.035253 \r\n",
      "    velocity:  abs. difference, ratio: 117.261429 , 0.012522 \r\n",
      "    aggregate: abs. difference, ratio: 159.225647 , 0.015086 \r\n",
      "Test sample 76\r\n",
      "    pressure:  abs. difference, ratio: 5.137075 , 0.019378 \r\n",
      "    velocity:  abs. difference, ratio: 25.643517 , 0.002981 \r\n",
      "    aggregate: abs. difference, ratio: 30.780590 , 0.003471 \r\n",
      "Test sample 77\r\n",
      "    pressure:  abs. difference, ratio: 25.014431 , 0.038803 \r\n",
      "    velocity:  abs. difference, ratio: 112.338974 , 0.012168 \r\n",
      "    aggregate: abs. difference, ratio: 137.353394 , 0.013907 \r\n",
      "Test sample 78\r\n",
      "    pressure:  abs. difference, ratio: 19.703091 , 0.039898 \r\n",
      "    velocity:  abs. difference, ratio: 67.458206 , 0.007343 \r\n",
      "    aggregate: abs. difference, ratio: 87.161301 , 0.009004 \r\n",
      "Test sample 79\r\n",
      "    pressure:  abs. difference, ratio: 201.944580 , 0.158927 \r\n",
      "    velocity:  abs. difference, ratio: 514.219421 , 0.052351 \r\n",
      "    aggregate: abs. difference, ratio: 716.163940 , 0.064558 \r\n",
      "Test sample 80\r\n",
      "    pressure:  abs. difference, ratio: 21.108271 , 0.042456 \r\n",
      "    velocity:  abs. difference, ratio: 74.082222 , 0.008058 \r\n",
      "    aggregate: abs. difference, ratio: 95.190498 , 0.009823 \r\n",
      "Test sample 81\r\n",
      "    pressure:  abs. difference, ratio: 82.061050 , 1.127900 \r\n",
      "    velocity:  abs. difference, ratio: 266.057526 , 0.032459 \r\n",
      "    aggregate: abs. difference, ratio: 348.118591 , 0.042097 \r\n",
      "Test sample 82\r\n",
      "    pressure:  abs. difference, ratio: 125.785889 , 0.122414 \r\n",
      "    velocity:  abs. difference, ratio: 369.023132 , 0.039727 \r\n",
      "    aggregate: abs. difference, ratio: 494.809021 , 0.047962 \r\n",
      "Test sample 83\r\n",
      "    pressure:  abs. difference, ratio: 68.926651 , 0.289956 \r\n",
      "    velocity:  abs. difference, ratio: 240.137589 , 0.027473 \r\n",
      "    aggregate: abs. difference, ratio: 309.064240 , 0.034422 \r\n",
      "Test sample 84\r\n",
      "    pressure:  abs. difference, ratio: 6.823384 , 0.018566 \r\n",
      "    velocity:  abs. difference, ratio: 30.196470 , 0.003477 \r\n",
      "    aggregate: abs. difference, ratio: 37.019852 , 0.004090 \r\n",
      "Test sample 85\r\n",
      "    pressure:  abs. difference, ratio: 584.275879 , 0.655371 \r\n",
      "    velocity:  abs. difference, ratio: 1762.677490 , 0.179559 \r\n",
      "    aggregate: abs. difference, ratio: 2346.953369 , 0.219173 \r\n",
      "Test sample 86\r\n",
      "    pressure:  abs. difference, ratio: 595.189575 , 0.667429 \r\n",
      "    velocity:  abs. difference, ratio: 1820.017090 , 0.185499 \r\n",
      "    aggregate: abs. difference, ratio: 2415.206787 , 0.225652 \r\n",
      "Test sample 87\r\n",
      "    pressure:  abs. difference, ratio: 139.560913 , 0.143844 \r\n",
      "    velocity:  abs. difference, ratio: 389.418945 , 0.041859 \r\n",
      "    aggregate: abs. difference, ratio: 528.979858 , 0.051490 \r\n",
      "Test sample 88\r\n",
      "    pressure:  abs. difference, ratio: 11.956187 , 0.042185 \r\n",
      "    velocity:  abs. difference, ratio: 38.102753 , 0.004318 \r\n",
      "    aggregate: abs. difference, ratio: 50.058941 , 0.005496 \r\n",
      "Test sample 89\r\n",
      "    pressure:  abs. difference, ratio: 9.289037 , 0.038148 \r\n",
      "    velocity:  abs. difference, ratio: 34.912872 , 0.004016 \r\n",
      "    aggregate: abs. difference, ratio: 44.201912 , 0.004947 \r\n",
      "\r\n",
      "\r\n",
      "Loss percentage (p, v, combined): 11.832533 %    2.140530 %    2.601584 % \r\n",
      "L1 error: 0.005337\r\n",
      "Denormalized error: 0.012800\r\n",
      "\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import os, sys, random, math\n",
    "import numpy as np\n",
    "import paddle\n",
    "import paddle.nn as nn\n",
    "from paddle.io import DataLoader\n",
    "import read_data\n",
    "from read_data import TurbDataset, ValiDataset\n",
    "from Unet_model import UNet2d\n",
    "from FNO_model import FNO2d\n",
    "from Trans_model import FourierTransformer2D\n",
    "import utils\n",
    "from utils import log\n",
    "from matplotlib import cm\n",
    "\n",
    "dropout = 0.0\n",
    "prop = [12800, 1.0, 0, 0.0]\n",
    "net = 'Transformer'\n",
    "expo = 7\n",
    "\n",
    "##########################\n",
    "\n",
    "data_path = os.path.join('data')\n",
    "train_path = os.path.join(data_path, 'train/')\n",
    "valid_path = os.path.join(data_path, 'test/')\n",
    "\n",
    "data = read_data.TurbDataset(prop, shuffle=1, dataDir=train_path, dataDirTest=valid_path)\n",
    "dataValidation = ValiDataset(data)\n",
    "validLoader = DataLoader(dataValidation, batch_size=1, shuffle=False, drop_last=True)\n",
    "print(\"Validation batches: {}\".format(len(validLoader)))\n",
    "\n",
    "dataset = TurbDataset(prop, mode=TurbDataset.TEST, dataDir=train_path, dataDirTest=valid_path)\n",
    "# dataset = TurbDataset(None, mode=TurbDataset.TEST, dataDirTest=\"../data/test/\")\n",
    "testLoader = DataLoader(dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "if 'UNet' in net:\n",
    "    net_model = UNet2d(channelExponent=expo, dropout=dropout)\n",
    "elif 'FNO' in net:\n",
    "    net_model = FNO2d(in_dim=3, out_dim=3, modes=(32, 32), width=32, depth=4, steps=1, padding=4, activation='gelu')\n",
    "elif 'Transformer' in net:\n",
    "    import yaml\n",
    "\n",
    "    with open(os.path.join('transformer_config.yml')) as f:\n",
    "        config = yaml.full_load(f)\n",
    "    config = config['Transformer']\n",
    "    net_model = FourierTransformer2D(**config)\n",
    "\n",
    "\n",
    "work_path = os.path.join('demo', net, \"prop-\" + str(prop), \"expo-\" + str(expo))\n",
    "\n",
    "prefix = work_path + \"/\"\n",
    "utils.makeDirs([prefix])\n",
    "print(\"Output prefix: {}\".format(prefix))\n",
    "\n",
    "lf = os.path.join('demo', net, \"prop-\" + str(prop), \"expo-\" + str(expo)) + \"/testout.txt\"\n",
    "utils.makeDirs([prefix + \"results_test\"])\n",
    "utils.resetLog(lf)\n",
    "\n",
    "modelFn = prefix + \"net_model\"\n",
    "\n",
    "log(lf, \"Loading \" + modelFn)\n",
    "net_model.set_state_dict(paddle.load(modelFn))\n",
    "log(lf, \"Loaded \" + modelFn)\n",
    "# netG.cuda()\n",
    "\n",
    "criterionL1 = nn.L1Loss()\n",
    "# criterionL1.cuda()\n",
    "L1val_accum = 0.0\n",
    "L1val_dn_accum = 0.0\n",
    "lossPer_p_accum = 0\n",
    "lossPer_v_accum = 0\n",
    "lossPer_accum = 0\n",
    "\n",
    "net_model.eval()\n",
    "\n",
    "for i, data in enumerate(testLoader, 0):\n",
    "    inputs, targets = data\n",
    "    with paddle.no_grad():\n",
    "        outputs = net_model(inputs)\n",
    "    outputs = outputs[0]\n",
    "    targets = targets[0]\n",
    "\n",
    "    lossL1 = criterionL1(outputs, targets)\n",
    "    L1val_accum += lossL1.item()\n",
    "\n",
    "    outputs = np.array(outputs)\n",
    "    targets = np.array(targets)\n",
    "\n",
    "    # precentage loss by ratio of means which is same as the ratio of the sum\n",
    "    lossPer_p = np.sum(np.abs(outputs[0] - targets[0])) / np.sum(np.abs(targets[0]))\n",
    "    lossPer_v = (np.sum(np.abs(outputs[1] - targets[1])) + np.sum(np.abs(outputs[2] - targets[2]))) \\\n",
    "                / (np.sum(np.abs(targets[1])) + np.sum(np.abs(targets[2])))\n",
    "    lossPer = np.sum(np.abs(outputs - targets)) / np.sum(np.abs(targets))\n",
    "    lossPer_p_accum += lossPer_p.item()\n",
    "    lossPer_v_accum += lossPer_v.item()\n",
    "    lossPer_accum += lossPer.item()\n",
    "\n",
    "    log(lf, \"Test sample %d\" % i)\n",
    "    log(lf, \"    pressure:  abs. difference, ratio: %f , %f \" % (np.sum(np.abs(outputs[0] - targets[0])),\n",
    "                                                                    lossPer_p.item()))\n",
    "    log(lf, \"    velocity:  abs. difference, ratio: %f , %f \" % (np.sum(np.abs(outputs[1] - targets[1])) +\n",
    "                                                                    np.sum(np.abs(outputs[2] - targets[2])),\n",
    "                                                                    lossPer_v.item()))\n",
    "    log(lf, \"    aggregate: abs. difference, ratio: %f , %f \" % (np.sum(np.abs(outputs - targets)),\n",
    "                                                                    lossPer.item()))\n",
    "\n",
    "    # Calculate the norm\n",
    "    input_ndarray = inputs.numpy()[0]\n",
    "    v_norm = (np.max(np.abs(input_ndarray[0, :, :])) ** 2 + np.max(np.abs(input_ndarray[1, :, :])) ** 2) ** 0.5\n",
    "\n",
    "    outputs_denormalized = dataset.denormalize(outputs, v_norm)\n",
    "    targets_denormalized = dataset.denormalize(targets, v_norm)\n",
    "\n",
    "    # denormalized error\n",
    "    outputs_denormalized_comp = np.array([outputs_denormalized])\n",
    "    # outputs_denormalized_comp=torch.from_numpy(outputs_denormalized_comp)\n",
    "    targets_denormalized_comp = np.array([targets_denormalized])\n",
    "    # targets_denormalized_comp=torch.from_numpy(targets_denormalized_comp)\n",
    "\n",
    "    # targets_denormalized_comp, outputs_denormalized_comp = targets_denormalized_comp.float().cuda(), outputs_denormalized_comp.float().cuda()\n",
    "\n",
    "    # outputs_dn.data.resize_as_(outputs_denormalized_comp).copy_(outputs_denormalized_comp)\n",
    "    # targets_dn.data.resize_as_(targets_denormalized_comp).copy_(targets_denormalized_comp)\n",
    "\n",
    "    outputs_dn = paddle.to_tensor(outputs_denormalized_comp)\n",
    "    targets_dn = paddle.to_tensor(targets_denormalized_comp)\n",
    "\n",
    "    lossL1_dn = criterionL1(outputs_dn, targets_dn)\n",
    "    L1val_dn_accum += lossL1_dn.item()\n",
    "\n",
    "    # write output image, note - this is currently overwritten for multiple models\n",
    "    utils.imageOut(prefix + \"results_test/\" + \"%04d\" % (i), outputs, targets, normalize=False,\n",
    "                    saveMontage=True, cmap=cm.RdBu_r)  # write normalized with error\n",
    "\n",
    "log(lf, \"\\n\")\n",
    "L1val_accum /= len(testLoader)\n",
    "lossPer_p_accum /= len(testLoader)\n",
    "lossPer_v_accum /= len(testLoader)\n",
    "lossPer_accum /= len(testLoader)\n",
    "L1val_dn_accum /= len(testLoader)\n",
    "log(lf, \"Loss percentage (p, v, combined): %f %%    %f %%    %f %% \" %\n",
    "    (lossPer_p_accum * 100, lossPer_v_accum * 100, lossPer_accum * 100))\n",
    "log(lf, \"L1 error: %f\" % (L1val_accum))\n",
    "log(lf, \"Denormalized error: %f\" % (L1val_dn_accum))\n",
    "log(lf, \"\\n\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "请点击[此处](https://ai.baidu.com/docs#/AIStudio_Project_Notebook/a38e5576)查看本环境基本用法.  <br>\n",
    "Please click [here ](https://ai.baidu.com/docs#/AIStudio_Project_Notebook/a38e5576) for more detailed instructions. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
